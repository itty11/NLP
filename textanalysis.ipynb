{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Text in the 'sentence' variable:\n",
      "Natural language processing makes it possible for computers to understand the human language. In natural language processing, human language is separated into fragments so that the grammatical structure of sentences and the meaning of words can be analyzed and understood in context. This helps computers read and understand spoken or written text in the same way as humans. I am studying Natural Language Processing at Amrita University.\n",
      "2. 'language' is in the text\n",
      "3. Index of 'human': 78\n",
      "4. Position of 'possible': 6\n",
      "5. Third word: processing\n",
      "6. Number of:\n",
      "a) Lines/Sentences: 4\n",
      "b) Words: 67\n",
      "c) Characters (excluding spaces): 372\n",
      "7. Vocabulary (list of unique words):\n",
      "['possible', 'in', 'meaning', 'to', 'language', 'human', 'sentences', 'way', 'as', 'at', 'natural', 'helps', 'same', 'university', 'amrita', 'i', 'separated', 'understood', 'studying', 'grammatical', 'spoken', 'so', 'into', 'be', 'context', 'understand', 'computers', 'fragments', 'this', 'it', 'for', 'makes', 'and', 'the', 'written', 'humans', 'is', 'processing', 'words', 'am', 'read', 'text', 'analyzed', 'of', 'can', 'or', 'that', 'structure']\n",
      "8. Words in the vocabulary along with their frequency:\n",
      "possible: 1\n",
      "in: 2\n",
      "meaning: 1\n",
      "to: 1\n",
      "language: 4\n",
      "human: 2\n",
      "sentences: 1\n",
      "way: 1\n",
      "as: 1\n",
      "at: 1\n",
      "natural: 1\n",
      "helps: 1\n",
      "same: 1\n",
      "university: 0\n",
      "amrita: 0\n",
      "i: 0\n",
      "separated: 1\n",
      "understood: 1\n",
      "studying: 1\n",
      "grammatical: 1\n",
      "spoken: 1\n",
      "so: 1\n",
      "into: 1\n",
      "be: 1\n",
      "context: 1\n",
      "understand: 2\n",
      "computers: 2\n",
      "fragments: 1\n",
      "this: 0\n",
      "it: 1\n",
      "for: 1\n",
      "makes: 1\n",
      "and: 3\n",
      "the: 4\n",
      "written: 1\n",
      "humans: 1\n",
      "is: 1\n",
      "processing: 2\n",
      "words: 1\n",
      "am: 1\n",
      "read: 1\n",
      "text: 1\n",
      "analyzed: 1\n",
      "of: 2\n",
      "can: 1\n",
      "or: 1\n",
      "that: 1\n",
      "structure: 1\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Natural language processing makes it possible for computers to understand the human language. In natural language processing, human language is separated into fragments so that the grammatical structure of sentences and the meaning of words can be analyzed and understood in context. This helps computers read and understand spoken or written text in the same way as humans. I am studying Natural Language Processing at Amrita University.\"\n",
    "\n",
    "print(\"1. Text in the 'sentence' variable:\")\n",
    "print(sentence)\n",
    "\n",
    "# Check whether the word ‘language’ belongs to that text\n",
    "if 'language' in sentence:\n",
    "    print(\"2. 'language' is in the text\")\n",
    "\n",
    "# Find out the  index  value of the word ‘human’\n",
    "human_index = sentence.index('human')\n",
    "print(f\"3. Index of 'human': {human_index}\")\n",
    "\n",
    "# Find out the position of the word ‘possible’\n",
    "words = sentence.split()\n",
    "possible_position = words.index('possible')\n",
    "print(f\"4. Position of 'possible': {possible_position + 1}\")\n",
    "\n",
    "# Print the third word of the given text\n",
    "third_word = words[2]\n",
    "print(f\"5. Third word: {third_word}\")\n",
    "\n",
    "# Split the text into lines/sentences, words, and characters (excluding spaces)\n",
    "lines = [line for line in sentence.split('.') if line]  # To remove empty elements\n",
    "words = re.findall(r'\\b\\w+\\b', sentence)  # To split words while ignoring punctuation\n",
    "characters = sentence.replace(\" \", \"\")\n",
    "\n",
    "# Count the number of lines, words, and characters\n",
    "num_lines = len(lines)\n",
    "num_words = len(words)\n",
    "num_characters = len(characters)\n",
    "\n",
    "print(\"6. Number of:\")\n",
    "print(f\"a) Lines/Sentences: {num_lines}\")\n",
    "print(f\"b) Words: {num_words}\")\n",
    "print(f\"c) Characters (excluding spaces): {num_characters}\")\n",
    "\n",
    "# Create a vocabulary (list of unique words, lowercased)\n",
    "vocabulary = list(set(word.lower() for word in words))\n",
    "\n",
    "print(\"7. Vocabulary (list of unique words):\")\n",
    "print(vocabulary)\n",
    "\n",
    "# List the words in the vocabulary along with their frequency (count)\n",
    "word_frequency = {word.lower(): words.count(word) for word in vocabulary}\n",
    "\n",
    "print(\"8. Words in the vocabulary along with their frequency:\")\n",
    "for word, count in word_frequency.items():\n",
    "    print(f\"{word}: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
